{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.go_order import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load child_parent_dirct from cache\n",
      "Load child_parent_full from cache\n"
     ]
    }
   ],
   "source": [
    "go = GO_order()\n",
    "go.init_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 04:59:40.235742: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 04:59:40.269685: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/evans/program/anaconda3/envs/atgo/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from Triplet_Network_Multiple_View import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU') dynamic memory growth enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 04:59:40.993049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 04:59:41.007357: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-19 04:59:41.007450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "use_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_par(tn):\n",
    "    tn.cut_off = cut_off\n",
    "    tn.layer_list = layer_list\n",
    "    tn.dropout_rate = dropout_rate\n",
    "    tn.learning_rate = learning_rate\n",
    "    tn.margin = margin\n",
    "    tn.alpha = alpha\n",
    "    tn.beta = beta\n",
    "    tn.weight = weight\n",
    "    tn.max_iteration = max_iteration\n",
    "    tn.batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = \"/media/evans/LabData/ATGO/New_Benchmark_history/model/My_benchmark_dataset\"\n",
    "types = ['MF', 'BP', 'CC']\n",
    "cut_off = 0.8\n",
    "layer_list = [1024]\n",
    "dropout_rate = 0.6\n",
    "learning_rate = 0.00015\n",
    "margin = 0.1\n",
    "alpha = 5.0\n",
    "beta = 2.0\n",
    "weight = 0.8\n",
    "max_iteration = 20\n",
    "batch_size = 512\n",
    "cur_round = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = Triplet_Network(workdir, types[0], cut_off, layer_list, dropout_rate, learning_rate,\n",
    "                             margin, alpha, beta, weight, max_iteration, batch_size, cur_round, 1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn.running()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = \"/media/evans/LabData/ATGO/New_Benchmark_history/model/My_benchmark_dataset\"\n",
    "types = ['MF', 'BP', 'CC']\n",
    "cut_off = 0.8\n",
    "layer_list = [1024]\n",
    "dropout_rate = 0.6\n",
    "learning_rate = 0.00015\n",
    "margin = 0.1\n",
    "alpha = 5.0\n",
    "beta = 2.0\n",
    "weight = 0.8\n",
    "max_iteration = 20\n",
    "batch_size = 512\n",
    "cur_round = 1\n",
    "update_par(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1 iteration: \n",
      "Training loss: 0.05710349102143755\n",
      "evaluate loss: 0.11183692125730144\n",
      "Testing loss: 0.11039875186915207\n",
      "The 2 iteration: \n",
      "Training loss: 0.056806472897259694\n",
      "evaluate loss: 0.11183937700483405\n",
      "Testing loss: 0.1103135109515909\n",
      "The 3 iteration: \n",
      "Training loss: 0.057076708199722645\n",
      "evaluate loss: 0.11178861993898466\n",
      "Testing loss: 0.11039122533653596\n",
      "The 4 iteration: \n",
      "Training loss: 0.05685344653643256\n",
      "evaluate loss: 0.11182337715787795\n",
      "Testing loss: 0.11051268372006805\n",
      "The 5 iteration: \n",
      "Training loss: 0.05725405519289707\n",
      "evaluate loss: 0.1118560838323195\n",
      "Testing loss: 0.11042976760316763\n",
      "The 6 iteration: \n",
      "Training loss: 0.05736432843743523\n",
      "evaluate loss: 0.11188014239362143\n",
      "Testing loss: 0.11049245864772714\n",
      "The 7 iteration: \n",
      "Training loss: 0.057114758015655485\n",
      "evaluate loss: 0.11199275275457253\n",
      "Testing loss: 0.11045006835636274\n",
      "The 8 iteration: \n",
      "Training loss: 0.057057637566859984\n",
      "evaluate loss: 0.1119107969032908\n",
      "Testing loss: 0.11045705192630378\n",
      "The 9 iteration: \n",
      "Training loss: 0.05670687337374231\n",
      "evaluate loss: 0.11186192686696654\n",
      "Testing loss: 0.11046122203046775\n",
      "The 10 iteration: \n",
      "Training loss: 0.05688036998541112\n",
      "evaluate loss: 0.11190010801825709\n",
      "Testing loss: 0.11045574522101073\n",
      "The 11 iteration: \n",
      "Training loss: 0.05668669201405606\n",
      "evaluate loss: 0.11192140459146314\n",
      "Testing loss: 0.11048719603277782\n",
      "The 12 iteration: \n",
      "Training loss: 0.05711183325426678\n",
      "evaluate loss: 0.11195283627625809\n",
      "Testing loss: 0.11044054163339026\n",
      "The 13 iteration: \n",
      "Training loss: 0.056974266238993564\n",
      "evaluate loss: 0.1118876603332538\n",
      "Testing loss: 0.11050777511745433\n",
      "The 14 iteration: \n",
      "Training loss: 0.05682801720112413\n",
      "evaluate loss: 0.11188207660774582\n",
      "Testing loss: 0.11048229450627878\n",
      "The 15 iteration: \n",
      "Training loss: 0.05691733487625931\n",
      "evaluate loss: 0.11203917218643485\n",
      "Testing loss: 0.11055291917956268\n",
      "The 16 iteration: \n",
      "Training loss: 0.056999657970212586\n",
      "evaluate loss: 0.11204687093646781\n",
      "Testing loss: 0.1105407141859238\n",
      "The 17 iteration: \n",
      "Training loss: 0.05693913856639714\n",
      "evaluate loss: 0.11209090138667996\n",
      "Testing loss: 0.11046367356847436\n",
      "The 18 iteration: \n",
      "Training loss: 0.056981297138021865\n",
      "evaluate loss: 0.11211730311217817\n",
      "Testing loss: 0.11045030820824245\n",
      "The 19 iteration: \n",
      "Training loss: 0.056544994640880454\n",
      "evaluate loss: 0.11223017380943576\n",
      "Testing loss: 0.11050781406191028\n",
      "The 20 iteration: \n",
      "Training loss: 0.05645692442327062\n",
      "evaluate loss: 0.11207408353107647\n",
      "Testing loss: 0.11046993190122435\n"
     ]
    }
   ],
   "source": [
    "tn.running(restore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atgo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
